{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуем метод predict_proba для KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже реализован класс KNeighborsClassifier, который для поиска ближайших соседей использует sklearn.neighbors.NearestNeighbors\n",
    "\n",
    "Требуется реализовать метод predict_proba для вычисления ответа классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "class KNeighborsClassifier(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Класс, который позволит нам изучить KNN\n",
    "    '''\n",
    "    def __init__(self, n_neighbors=5, weights='uniform', \n",
    "                 metric='minkowski', p=2):\n",
    "        '''\n",
    "        Инициализируем KNN с несколькими стандартными параметрами\n",
    "        '''\n",
    "        assert weights in ('uniform', 'distance')\n",
    "        \n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.NearestNeighbors = NearestNeighbors(\n",
    "            n_neighbors = n_neighbors,\n",
    "            metric = self.metric)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Используем sklearn.neighbors.NearestNeighbors \n",
    "        для запоминания обучающей выборки\n",
    "        и последующего поиска соседей\n",
    "        '''\n",
    "        self.NearestNeighbors.fit(X)\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.y = y\n",
    "    def predict_proba(self, X, use_first_zero_distant_sample=True):\n",
    "        '''\n",
    "        Чтобы реализовать этот метод, \n",
    "        \n",
    "        изучите работу sklearn.neighbors.NearestNeighbors\n",
    "        '''\n",
    "        # получим здесь расстояния до соседей distances и их метки\n",
    "        distances, indexes = self.NearestNeighbors.kneighbors(X)\n",
    "        \n",
    "        probs = np.ones((X.shape[0], np.unique(y[indexes]).shape[0]))\n",
    "        #print(probs)\n",
    "        if self.weights == 'uniform':\n",
    "            w = np.ones(distances.shape)\n",
    "        else:\n",
    "            # чтобы не делить на 0, \n",
    "            # добавим небольшую константу, например 1e-3\n",
    "            w = 1/(distances + 1e-3)\n",
    "        \n",
    "        # реализуем вычисление предсказаний:\n",
    "        # выбрав один объект, для каждого класса посчитаем\n",
    "        # суммарный вес голосующих за него объектов\n",
    "        # затем нормируем эти веса на их сумму\n",
    "        # и вернем это как предсказание KNN\n",
    "        \n",
    "        w_class = 0\n",
    "        \n",
    "        norm = np.sum(w, axis=1)\n",
    "        \n",
    "        print(\"Classes: \", y[indexes])\n",
    "        \n",
    "        for class_n in range(np.unique(y[indexes]).shape[0]):\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(distances.shape[1]):\n",
    "                    if  class_n == y[indexes][i, j]:\n",
    "                        w_class += w[i, j]\n",
    "                probs[i, class_n] *= w_class/norm[i]\n",
    "                w_class = 0\n",
    "        print(\"Probs: \", probs)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные и обучим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 2 1]\n",
      " [1 1 1 1 1]\n",
      " [1 2 2 2 1]\n",
      " [1 1 1 1 1]\n",
      " [1 2 2 2 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 2 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 2 2 2 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 1 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 1 1 1 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 1 1 2 2]\n",
      " [2 2 1 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 1 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]]\n",
      "Probs:  [[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.99784618 0.00215382]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.99816311 0.00183689]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.98959384 0.01040616]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.99212993 0.00787007]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.99527902 0.00472098]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.98892092 0.01107908]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00504138 0.99495862]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00232401 0.99767599]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00601644 0.99398356]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00272405 0.99727595]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00326373 0.99673627]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00571063 0.99428937]\n",
      " [0.         0.00178061 0.99821939]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00437286 0.99562714]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.00239145 0.99760855]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance')\n",
    "knn.fit(X, y)\n",
    "prediction = knn.predict_proba(X, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы используем одну и ту же выборку для обучения и предсказания, ближайшим соседом любого объекта будет он же сам. В качестве упражнения предлагаю реализовать метод transform, который реализует получение предсказаний для обучающей выборки, но для каждого объекта не будет учитывать его самого.\n",
    "\n",
    "Посмотрим, в каких объектах max(prediction) != 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 56  68  70  72  77  83 106 110 119 123 127 133 134 138 146]\n"
     ]
    }
   ],
   "source": [
    "inds = np.arange(len(prediction))[prediction.max(1) != 1]\n",
    "print(inds)\n",
    "\n",
    "# [ 56  68  70  72  77  83 106 110 119 123 127 133 134 138 146]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько примеров, на которых можно проверить правильность реализованного метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 [0.         0.99816311 0.00183689]\n",
      "77 [0.         0.99527902 0.00472098]\n",
      "146 [0.         0.00239145 0.99760855]\n"
     ]
    }
   ],
   "source": [
    "for i in 1, 4, -1:\n",
    "    print(inds[i], prediction[inds[i]])\n",
    "\n",
    "# 68 [0.         0.99816311 0.00183689]\n",
    "# 77 [0.         0.99527902 0.00472098]\n",
    "# 146 [0.         0.00239145 0.99760855]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответы для формы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В форму требуется ввести max(prediction) для объекта. Если метод реализован верно, то ячейка ниже распечатает ответы, которые нужно ввести в форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 56, 83, 127:\n",
    "    print('{:.4f}'.format(max(prediction[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "probs = np.ones((2, 3))\n",
    "\n",
    "#print(probs)\n",
    "\n",
    "w = np.array([\n",
    "    [1.00000000e+03, 9.90099010e+00, 7.02141888e+00, 7.02141888e+00, 7.02141888e+00], \n",
    "    [1.00000000e+03, 7.02141888e+00, 5.74036070e+00, 5.74036070e+00, 4.45222500e+00]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [2, 0, 1, 2, 2],\n",
    "    [1, 1, 2, 0, 0]\n",
    "])\n",
    "\n",
    "w_class = 0\n",
    "\n",
    "norm = np.sum(w, axis = 1)\n",
    "\n",
    "print(\"norm\", norm)\n",
    "\n",
    "for n_classes in range(3):\n",
    "    for i in range(2):\n",
    "        #print(\"Looking for class: \", n_classes)\n",
    "        #print(\"Object: \", i)\n",
    "        for j in range(5):\n",
    "            #print(y[i,j])\n",
    "            if n_classes == y[i, j]:\n",
    "                #print(\"Found the class \", y[i,j], \"!\")\n",
    "                w_class += w[i, j]\n",
    "                #print(\"w_class: \", w_class)\n",
    "        #print(\"norm: \", norm[i])\n",
    "        probs[i, n_classes] *= w_class/norm[i]\n",
    "        #print(\"probs: \", probs)\n",
    "        w_class = 0\n",
    "\n",
    "probs.sum(axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMIA_2018",
   "language": "python",
   "name": "dmia_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
